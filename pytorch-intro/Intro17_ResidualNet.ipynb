{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a Mini Resnet to classify CIFAR10 \n",
    "www.bigrabbitdata.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "joVBzx_67BjN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import PIL.ImageOps\n",
    "import requests\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RHcpXtTNaCLt"
   },
   "source": [
    "## Data Augmentation for Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "QWAcFfg574GU",
    "outputId": "1b6e22cf-23ba-4e22-cbf6-30ce14127e5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                                     std=[0.247, 0.243, 0.261])\n",
    "\n",
    "transform  = transforms.Compose([transforms.Resize((32,32)),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 normalize\n",
    "                                ])\n",
    "transform_train = transforms.Compose([transforms.Resize((32,32)),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomRotation(10),\n",
    "                                      transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "                                      transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      normalize\n",
    "                               ])\n",
    "\n",
    "training_dataset = datasets.CIFAR10(root='./cifar10', train=True, \n",
    "                                  download=True, transform= transform_train)\n",
    "validation_dataset = datasets.CIFAR10(root='./cifar10', train=False, \n",
    "                                  download=True, transform= transform) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4lQTuzOsaFvH"
   },
   "source": [
    "## Adjust model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0u4k_DIh77oC"
   },
   "outputs": [],
   "source": [
    "# A fixed 3x3 kernel_size conv filter\n",
    "# Bias term is omited , as the author said it is in the batch_norm layer\n",
    "# https://github.com/KaimingHe/deep-residual-networks/issues/10#issuecomment-194037195\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    '''\n",
    "        Conv--> Batchnorm-->ReLu-->Conv-->Batchnorm--> \n",
    "        Only downsample if needed\n",
    "    '''\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(3, 16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        # Only downsample when stride is not 2 \n",
    "        # or when input channel doesn't match output channel\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                                       nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        # append the first residual block for each layer \n",
    "        # downsample the image if needed\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        # append the suceeding residual block in each layer\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CFElHQGw78Yq",
    "outputId": "71d4b4c2-9a46-4be3-f0e2-db201b12470f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [10000/50000 (20%)] Loss: 1.797894\n",
      "Train Epoch: 1 [20000/50000 (40%)] Loss: 1.542277\n",
      "Train Epoch: 1 [30000/50000 (60%)] Loss: 1.429435\n",
      "Train Epoch: 1 [40000/50000 (80%)] Loss: 1.320243\n",
      "Train Epoch: 1 [50000/50000 (100%)] Loss: 1.249881\n",
      "epoch : 1\n",
      "Train set: Accuracy: 23043.0/50000 (46%), Average Loss: 1.467946\n",
      "Validation set: Accuracy: 5873.0/10000 (59%), Average Loss: 0.228339\n",
      "Train Epoch: 2 [10000/50000 (20%)] Loss: 1.157408\n",
      "Train Epoch: 2 [20000/50000 (40%)] Loss: 1.129108\n",
      "Train Epoch: 2 [30000/50000 (60%)] Loss: 1.123871\n",
      "Train Epoch: 2 [40000/50000 (80%)] Loss: 1.078017\n",
      "Train Epoch: 2 [50000/50000 (100%)] Loss: 1.032543\n",
      "epoch : 2\n",
      "Train set: Accuracy: 30310.0/50000 (61%), Average Loss: 1.104190\n",
      "Validation set: Accuracy: 6550.0/10000 (66%), Average Loss: 0.194203\n",
      "Train Epoch: 3 [10000/50000 (20%)] Loss: 1.019314\n",
      "Train Epoch: 3 [20000/50000 (40%)] Loss: 0.966754\n",
      "Train Epoch: 3 [30000/50000 (60%)] Loss: 0.980783\n",
      "Train Epoch: 3 [40000/50000 (80%)] Loss: 0.951569\n",
      "Train Epoch: 3 [50000/50000 (100%)] Loss: 0.923853\n",
      "epoch : 3\n",
      "Train set: Accuracy: 32792.0/50000 (66%), Average Loss: 0.968455\n",
      "Validation set: Accuracy: 7071.0/10000 (71%), Average Loss: 0.164633\n",
      "Train Epoch: 4 [10000/50000 (20%)] Loss: 0.893888\n",
      "Train Epoch: 4 [20000/50000 (40%)] Loss: 0.876455\n",
      "Train Epoch: 4 [30000/50000 (60%)] Loss: 0.889313\n",
      "Train Epoch: 4 [40000/50000 (80%)] Loss: 0.847419\n",
      "Train Epoch: 4 [50000/50000 (100%)] Loss: 0.835875\n",
      "epoch : 4\n",
      "Train set: Accuracy: 34667.0/50000 (69%), Average Loss: 0.868590\n",
      "Validation set: Accuracy: 7221.0/10000 (72%), Average Loss: 0.157655\n",
      "Train Epoch: 5 [10000/50000 (20%)] Loss: 0.812958\n",
      "Train Epoch: 5 [20000/50000 (40%)] Loss: 0.811607\n",
      "Train Epoch: 5 [30000/50000 (60%)] Loss: 0.787240\n",
      "Train Epoch: 5 [40000/50000 (80%)] Loss: 0.799828\n",
      "Train Epoch: 5 [50000/50000 (100%)] Loss: 0.795041\n",
      "epoch : 5\n",
      "Train set: Accuracy: 35915.0/50000 (72%), Average Loss: 0.801335\n",
      "Validation set: Accuracy: 7547.0/10000 (75%), Average Loss: 0.137953\n",
      "Train Epoch: 6 [10000/50000 (20%)] Loss: 0.746176\n",
      "Train Epoch: 6 [20000/50000 (40%)] Loss: 0.748718\n",
      "Train Epoch: 6 [30000/50000 (60%)] Loss: 0.751959\n",
      "Train Epoch: 6 [40000/50000 (80%)] Loss: 0.745552\n",
      "Train Epoch: 6 [50000/50000 (100%)] Loss: 0.744171\n",
      "epoch : 6\n",
      "Train set: Accuracy: 36845.0/50000 (74%), Average Loss: 0.747315\n",
      "Validation set: Accuracy: 7716.0/10000 (77%), Average Loss: 0.131816\n",
      "Train Epoch: 7 [10000/50000 (20%)] Loss: 0.714061\n",
      "Train Epoch: 7 [20000/50000 (40%)] Loss: 0.724053\n",
      "Train Epoch: 7 [30000/50000 (60%)] Loss: 0.715296\n",
      "Train Epoch: 7 [40000/50000 (80%)] Loss: 0.699461\n",
      "Train Epoch: 7 [50000/50000 (100%)] Loss: 0.712327\n",
      "epoch : 7\n",
      "Train set: Accuracy: 37620.0/50000 (75%), Average Loss: 0.713040\n",
      "Validation set: Accuracy: 7862.0/10000 (79%), Average Loss: 0.123791\n",
      "Train Epoch: 8 [10000/50000 (20%)] Loss: 0.685623\n",
      "Train Epoch: 8 [20000/50000 (40%)] Loss: 0.667655\n",
      "Train Epoch: 8 [30000/50000 (60%)] Loss: 0.664730\n",
      "Train Epoch: 8 [40000/50000 (80%)] Loss: 0.683901\n",
      "Train Epoch: 8 [50000/50000 (100%)] Loss: 0.680033\n",
      "epoch : 8\n",
      "Train set: Accuracy: 38202.0/50000 (76%), Average Loss: 0.676388\n",
      "Validation set: Accuracy: 7938.0/10000 (79%), Average Loss: 0.119858\n",
      "Train Epoch: 9 [10000/50000 (20%)] Loss: 0.656992\n",
      "Train Epoch: 9 [20000/50000 (40%)] Loss: 0.645936\n",
      "Train Epoch: 9 [30000/50000 (60%)] Loss: 0.634301\n",
      "Train Epoch: 9 [40000/50000 (80%)] Loss: 0.667265\n",
      "Train Epoch: 9 [50000/50000 (100%)] Loss: 0.639709\n",
      "epoch : 9\n",
      "Train set: Accuracy: 38785.0/50000 (78%), Average Loss: 0.648841\n",
      "Validation set: Accuracy: 8014.0/10000 (80%), Average Loss: 0.116154\n",
      "Train Epoch: 10 [10000/50000 (20%)] Loss: 0.624660\n",
      "Train Epoch: 10 [20000/50000 (40%)] Loss: 0.656874\n",
      "Train Epoch: 10 [30000/50000 (60%)] Loss: 0.621590\n",
      "Train Epoch: 10 [40000/50000 (80%)] Loss: 0.623944\n",
      "Train Epoch: 10 [50000/50000 (100%)] Loss: 0.623593\n",
      "epoch : 10\n",
      "Train set: Accuracy: 39010.0/50000 (78%), Average Loss: 0.630132\n",
      "Validation set: Accuracy: 8075.0/10000 (81%), Average Loss: 0.115070\n",
      "Train Epoch: 11 [10000/50000 (20%)] Loss: 0.611870\n",
      "Train Epoch: 11 [20000/50000 (40%)] Loss: 0.599480\n",
      "Train Epoch: 11 [30000/50000 (60%)] Loss: 0.624090\n",
      "Train Epoch: 11 [40000/50000 (80%)] Loss: 0.610845\n",
      "Train Epoch: 11 [50000/50000 (100%)] Loss: 0.604781\n",
      "epoch : 11\n",
      "Train set: Accuracy: 39291.0/50000 (79%), Average Loss: 0.610213\n",
      "Validation set: Accuracy: 8072.0/10000 (81%), Average Loss: 0.110131\n",
      "Train Epoch: 12 [10000/50000 (20%)] Loss: 0.596429\n",
      "Train Epoch: 12 [20000/50000 (40%)] Loss: 0.596817\n",
      "Train Epoch: 12 [30000/50000 (60%)] Loss: 0.595694\n",
      "Train Epoch: 12 [40000/50000 (80%)] Loss: 0.571547\n",
      "Train Epoch: 12 [50000/50000 (100%)] Loss: 0.581870\n",
      "epoch : 12\n",
      "Train set: Accuracy: 39712.0/50000 (79%), Average Loss: 0.588472\n",
      "Validation set: Accuracy: 8138.0/10000 (81%), Average Loss: 0.109876\n",
      "Train Epoch: 13 [10000/50000 (20%)] Loss: 0.576693\n",
      "Train Epoch: 13 [20000/50000 (40%)] Loss: 0.572645\n",
      "Train Epoch: 13 [30000/50000 (60%)] Loss: 0.571668\n",
      "Train Epoch: 13 [40000/50000 (80%)] Loss: 0.567507\n",
      "Train Epoch: 13 [50000/50000 (100%)] Loss: 0.567923\n",
      "epoch : 13\n",
      "Train set: Accuracy: 40087.0/50000 (80%), Average Loss: 0.571287\n",
      "Validation set: Accuracy: 8212.0/10000 (82%), Average Loss: 0.103296\n",
      "Train Epoch: 14 [10000/50000 (20%)] Loss: 0.557373\n",
      "Train Epoch: 14 [20000/50000 (40%)] Loss: 0.556246\n",
      "Train Epoch: 14 [30000/50000 (60%)] Loss: 0.557951\n",
      "Train Epoch: 14 [40000/50000 (80%)] Loss: 0.554191\n",
      "Train Epoch: 14 [50000/50000 (100%)] Loss: 0.553933\n",
      "epoch : 14\n",
      "Train set: Accuracy: 40237.0/50000 (80%), Average Loss: 0.555939\n",
      "Validation set: Accuracy: 8190.0/10000 (82%), Average Loss: 0.101903\n",
      "Train Epoch: 15 [10000/50000 (20%)] Loss: 0.527538\n",
      "Train Epoch: 15 [20000/50000 (40%)] Loss: 0.547593\n",
      "Train Epoch: 15 [30000/50000 (60%)] Loss: 0.544365\n",
      "Train Epoch: 15 [40000/50000 (80%)] Loss: 0.559490\n",
      "Train Epoch: 15 [50000/50000 (100%)] Loss: 0.540338\n",
      "epoch : 15\n",
      "Train set: Accuracy: 40514.0/50000 (81%), Average Loss: 0.543864\n",
      "Validation set: Accuracy: 8268.0/10000 (83%), Average Loss: 0.099873\n",
      "Train Epoch: 16 [10000/50000 (20%)] Loss: 0.491189\n",
      "Train Epoch: 16 [20000/50000 (40%)] Loss: 0.484150\n",
      "Train Epoch: 16 [30000/50000 (60%)] Loss: 0.486551\n",
      "Train Epoch: 16 [40000/50000 (80%)] Loss: 0.492592\n",
      "Train Epoch: 16 [50000/50000 (100%)] Loss: 0.487017\n",
      "epoch : 16\n",
      "Train set: Accuracy: 41405.0/50000 (83%), Average Loss: 0.488300\n",
      "Validation set: Accuracy: 8399.0/10000 (84%), Average Loss: 0.091287\n",
      "Train Epoch: 17 [10000/50000 (20%)] Loss: 0.474841\n",
      "Train Epoch: 17 [20000/50000 (40%)] Loss: 0.472041\n",
      "Train Epoch: 17 [30000/50000 (60%)] Loss: 0.494853\n",
      "Train Epoch: 17 [40000/50000 (80%)] Loss: 0.468000\n",
      "Train Epoch: 17 [50000/50000 (100%)] Loss: 0.466682\n",
      "epoch : 17\n",
      "Train set: Accuracy: 41730.0/50000 (83%), Average Loss: 0.475283\n",
      "Validation set: Accuracy: 8423.0/10000 (84%), Average Loss: 0.092174\n",
      "Train Epoch: 18 [10000/50000 (20%)] Loss: 0.463447\n",
      "Train Epoch: 18 [20000/50000 (40%)] Loss: 0.469365\n",
      "Train Epoch: 18 [30000/50000 (60%)] Loss: 0.458800\n",
      "Train Epoch: 18 [40000/50000 (80%)] Loss: 0.473194\n",
      "Train Epoch: 18 [50000/50000 (100%)] Loss: 0.460150\n",
      "epoch : 18\n",
      "Train set: Accuracy: 41869.0/50000 (84%), Average Loss: 0.464991\n",
      "Validation set: Accuracy: 8422.0/10000 (84%), Average Loss: 0.091168\n",
      "Train Epoch: 19 [10000/50000 (20%)] Loss: 0.458015\n",
      "Train Epoch: 19 [20000/50000 (40%)] Loss: 0.472032\n",
      "Train Epoch: 19 [30000/50000 (60%)] Loss: 0.450575\n",
      "Train Epoch: 19 [40000/50000 (80%)] Loss: 0.458855\n",
      "Train Epoch: 19 [50000/50000 (100%)] Loss: 0.447341\n",
      "epoch : 19\n",
      "Train set: Accuracy: 42022.0/50000 (84%), Average Loss: 0.457364\n",
      "Validation set: Accuracy: 8421.0/10000 (84%), Average Loss: 0.090301\n",
      "Train Epoch: 20 [10000/50000 (20%)] Loss: 0.448447\n",
      "Train Epoch: 20 [20000/50000 (40%)] Loss: 0.444560\n",
      "Train Epoch: 20 [30000/50000 (60%)] Loss: 0.461640\n",
      "Train Epoch: 20 [40000/50000 (80%)] Loss: 0.448928\n",
      "Train Epoch: 20 [50000/50000 (100%)] Loss: 0.459661\n",
      "epoch : 20\n",
      "Train set: Accuracy: 42069.0/50000 (84%), Average Loss: 0.452647\n",
      "Validation set: Accuracy: 8425.0/10000 (84%), Average Loss: 0.091424\n",
      "Train Epoch: 21 [10000/50000 (20%)] Loss: 0.440738\n",
      "Train Epoch: 21 [20000/50000 (40%)] Loss: 0.449508\n",
      "Train Epoch: 21 [30000/50000 (60%)] Loss: 0.441848\n",
      "Train Epoch: 21 [40000/50000 (80%)] Loss: 0.448281\n",
      "Train Epoch: 21 [50000/50000 (100%)] Loss: 0.437295\n",
      "epoch : 21\n",
      "Train set: Accuracy: 42216.0/50000 (84%), Average Loss: 0.443534\n",
      "Validation set: Accuracy: 8447.0/10000 (84%), Average Loss: 0.088980\n",
      "Train Epoch: 22 [10000/50000 (20%)] Loss: 0.444215\n",
      "Train Epoch: 22 [20000/50000 (40%)] Loss: 0.434669\n",
      "Train Epoch: 22 [30000/50000 (60%)] Loss: 0.424874\n",
      "Train Epoch: 22 [40000/50000 (80%)] Loss: 0.449828\n",
      "Train Epoch: 22 [50000/50000 (100%)] Loss: 0.442099\n",
      "epoch : 22\n",
      "Train set: Accuracy: 42329.0/50000 (85%), Average Loss: 0.439137\n",
      "Validation set: Accuracy: 8465.0/10000 (85%), Average Loss: 0.088029\n",
      "Train Epoch: 23 [10000/50000 (20%)] Loss: 0.429098\n",
      "Train Epoch: 23 [20000/50000 (40%)] Loss: 0.416805\n",
      "Train Epoch: 23 [30000/50000 (60%)] Loss: 0.450658\n",
      "Train Epoch: 23 [40000/50000 (80%)] Loss: 0.424598\n",
      "Train Epoch: 23 [50000/50000 (100%)] Loss: 0.438310\n",
      "epoch : 23\n",
      "Train set: Accuracy: 42411.0/50000 (85%), Average Loss: 0.431894\n",
      "Validation set: Accuracy: 8513.0/10000 (85%), Average Loss: 0.085200\n",
      "Train Epoch: 24 [10000/50000 (20%)] Loss: 0.418396\n",
      "Train Epoch: 24 [20000/50000 (40%)] Loss: 0.441358\n",
      "Train Epoch: 24 [30000/50000 (60%)] Loss: 0.422213\n",
      "Train Epoch: 24 [40000/50000 (80%)] Loss: 0.428235\n",
      "Train Epoch: 24 [50000/50000 (100%)] Loss: 0.424572\n",
      "epoch : 24\n",
      "Train set: Accuracy: 42499.0/50000 (85%), Average Loss: 0.426955\n",
      "Validation set: Accuracy: 8502.0/10000 (85%), Average Loss: 0.086154\n",
      "Train Epoch: 25 [10000/50000 (20%)] Loss: 0.403838\n",
      "Train Epoch: 25 [20000/50000 (40%)] Loss: 0.420416\n",
      "Train Epoch: 25 [30000/50000 (60%)] Loss: 0.422837\n",
      "Train Epoch: 25 [40000/50000 (80%)] Loss: 0.436269\n",
      "Train Epoch: 25 [50000/50000 (100%)] Loss: 0.424207\n",
      "epoch : 25\n",
      "Train set: Accuracy: 42664.0/50000 (85%), Average Loss: 0.421513\n",
      "Validation set: Accuracy: 8557.0/10000 (86%), Average Loss: 0.084881\n",
      "Train Epoch: 26 [10000/50000 (20%)] Loss: 0.410618\n",
      "Train Epoch: 26 [20000/50000 (40%)] Loss: 0.416941\n",
      "Train Epoch: 26 [30000/50000 (60%)] Loss: 0.409682\n",
      "Train Epoch: 26 [40000/50000 (80%)] Loss: 0.428732\n",
      "Train Epoch: 26 [50000/50000 (100%)] Loss: 0.409786\n",
      "epoch : 26\n",
      "Train set: Accuracy: 42701.0/50000 (85%), Average Loss: 0.415152\n",
      "Validation set: Accuracy: 8560.0/10000 (86%), Average Loss: 0.084254\n",
      "Train Epoch: 27 [10000/50000 (20%)] Loss: 0.401311\n",
      "Train Epoch: 27 [20000/50000 (40%)] Loss: 0.425856\n",
      "Train Epoch: 27 [30000/50000 (60%)] Loss: 0.413840\n",
      "Train Epoch: 27 [40000/50000 (80%)] Loss: 0.424690\n",
      "Train Epoch: 27 [50000/50000 (100%)] Loss: 0.416542\n",
      "epoch : 27\n",
      "Train set: Accuracy: 42635.0/50000 (85%), Average Loss: 0.416448\n",
      "Validation set: Accuracy: 8521.0/10000 (85%), Average Loss: 0.084599\n",
      "Train Epoch: 28 [10000/50000 (20%)] Loss: 0.404079\n",
      "Train Epoch: 28 [20000/50000 (40%)] Loss: 0.408972\n",
      "Train Epoch: 28 [30000/50000 (60%)] Loss: 0.401206\n",
      "Train Epoch: 28 [40000/50000 (80%)] Loss: 0.396909\n",
      "Train Epoch: 28 [50000/50000 (100%)] Loss: 0.425986\n",
      "epoch : 28\n",
      "Train set: Accuracy: 42805.0/50000 (86%), Average Loss: 0.407431\n",
      "Validation set: Accuracy: 8563.0/10000 (86%), Average Loss: 0.082690\n",
      "Train Epoch: 29 [10000/50000 (20%)] Loss: 0.389473\n",
      "Train Epoch: 29 [20000/50000 (40%)] Loss: 0.405471\n",
      "Train Epoch: 29 [30000/50000 (60%)] Loss: 0.407229\n",
      "Train Epoch: 29 [40000/50000 (80%)] Loss: 0.411584\n",
      "Train Epoch: 29 [50000/50000 (100%)] Loss: 0.410376\n",
      "epoch : 29\n",
      "Train set: Accuracy: 42929.0/50000 (86%), Average Loss: 0.404826\n",
      "Validation set: Accuracy: 8542.0/10000 (85%), Average Loss: 0.083515\n",
      "Train Epoch: 30 [10000/50000 (20%)] Loss: 0.409227\n",
      "Train Epoch: 30 [20000/50000 (40%)] Loss: 0.389715\n",
      "Train Epoch: 30 [30000/50000 (60%)] Loss: 0.405654\n",
      "Train Epoch: 30 [40000/50000 (80%)] Loss: 0.395512\n",
      "Train Epoch: 30 [50000/50000 (100%)] Loss: 0.393426\n",
      "epoch : 30\n",
      "Train set: Accuracy: 43003.0/50000 (86%), Average Loss: 0.398707\n",
      "Validation set: Accuracy: 8571.0/10000 (86%), Average Loss: 0.082836\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "model = ResNet(ResidualBlock, [2, 2, 2]).to(device)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(dataset=training_dataset, \n",
    "                                              batch_size=100,\n",
    "                                              shuffle=True)\n",
    "   \n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, \n",
    "                                              batch_size=100,\n",
    "                                              shuffle=True)\n",
    "\n",
    "# Cross Entropy Loss with Adam Optimizer \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "# Set up learning rate scheduler, decay lr by 0.5 every 15 epochs\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)\n",
    "\n",
    "train_corrects_history = []\n",
    "val_corrects_history = []\n",
    "\n",
    "epochs = 30\n",
    "for e in range(epochs):\n",
    "\n",
    "    train_corrects = 0.0 \n",
    "    train_batch_loss = 0.0\n",
    "    train_epoch_loss = 0.0\n",
    "    val_corrects = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # loop through 60000 samples 100 at a time\n",
    "    for batch_idx, data in enumerate(training_loader, start=1):\n",
    "        inputs = data[0].to(device)\n",
    "        labels = data[1].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Return the index of the highest possibility\n",
    "        # which are the predicted labels\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_batch_loss += loss.item()\n",
    "\n",
    "        # sum up all the correct prediction\n",
    "        # since (preds==labels).sum() is a tensor\n",
    "        # we use item() to extract the number\n",
    "        train_corrects += (preds == labels).sum().item()\n",
    "\n",
    "        # print training loss every 100 mini-batch\n",
    "        # train_batch_loss is the average loss for 100 mini-batch\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.6f}'.format(\n",
    "                   e + 1 , \n",
    "                   batch_idx * len(data[0]), \n",
    "                   len(training_loader.dataset),\n",
    "                   100.* batch_idx * len(data[0]) / len(training_loader.dataset), \n",
    "                   train_batch_loss / 100 ))\n",
    "            # accumulate loss for the epoch\n",
    "            train_epoch_loss += train_batch_loss\n",
    "            # reset the loss for every mini-batch\n",
    "            train_batch_loss = 0.0\n",
    "    else:\n",
    "        # torch.no_grad deactivate the auograd engine, \n",
    "        # reduce memory usage and speed up computations\n",
    "        with torch.no_grad():\n",
    "            for val_data in validation_loader:\n",
    "                val_inputs = val_data[0].to(device)\n",
    "                val_labels = val_data[1].to(device)\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss = criterion(val_outputs, val_labels)\n",
    "\n",
    "                _, val_preds = torch.max(val_outputs, 1)\n",
    "                val_epoch_loss += val_loss.item()\n",
    "                val_corrects += (val_preds == val_labels).sum().item()\n",
    "\n",
    "\n",
    "        # print result for every epoch \n",
    "        train_accuracy = 100. * train_corrects / len(training_loader.dataset)\n",
    "        train_corrects_history.append(train_accuracy)\n",
    "        # here batch_idx is the total number of mini-batch = 600\n",
    "        train_epoch_loss /= batch_idx\n",
    "\n",
    "        print('epoch :', (e+1))\n",
    "        print('Train set: Accuracy: {}/{} ({:.0f}%), Average Loss: {:.6f}'.format(\n",
    "                train_corrects, len(training_loader.dataset),\n",
    "                train_accuracy, train_epoch_loss))\n",
    "\n",
    "\n",
    "        \n",
    "        val_accuracy = 100. * val_corrects / len(validation_loader.dataset)\n",
    "        val_corrects_history.append(val_accuracy)\n",
    "        val_epoch_loss /= batch_idx\n",
    "\n",
    "        print('Validation set: Accuracy: {}/{} ({:.0f}%), Average Loss: {:.6f}'.format(\n",
    "                val_corrects, len(validation_loader.dataset),\n",
    "                val_accuracy, val_epoch_loss))\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "6HD2kKFlFRw5",
    "outputId": "4740602d-36d2-4e48-ed80-bf7890f052d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20a01c79c70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_corrects_history, label='training accuracy')\n",
    "plt.plot(val_corrects_history, label='validation accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Pytorch 12: CIFAR10_V2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
